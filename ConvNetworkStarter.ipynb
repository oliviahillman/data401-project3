{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1000\n",
    "NUM_EPOCHS = 10\n",
    "#STEPS_PER_EPOCH = 30\n",
    "START_LEARNING_RATE = 0.003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_function():\n",
    "    # a layer instance is callable on a tensor, and returns a tensor\n",
    "    model = tf.keras.Sequential([\n",
    "        Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                      data_format='channels_last',\n",
    "                      activation='relu',\n",
    "                      input_shape=(13, 13, 1)),\n",
    "        MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(START_LEARNING_RATE),\n",
    "              loss='mse',       # mean squared error\n",
    "              metrics=['mae'])  # mean absolute error\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 13, 13, 1) (100000, 2)\n"
     ]
    }
   ],
   "source": [
    "with open('data/board_states.npy', 'rb') as boards_file, \\\n",
    "    open('data/winners.npy', 'rb') as winners_file:\n",
    "    boards = np.load(boards_file)\n",
    "    winners = np.load(winners_file)\n",
    "    \n",
    "    winners_cat = np.array([[1.0, 0.0] if x==1 else [0.0, 1.0] for x in winners])\n",
    "\n",
    "    print(boards[:100000, :, :, :].shape, winners_cat[:100000, :].shape)\n",
    "    \n",
    "    nums = np.arange(len(winners_cat))\n",
    "    np.random.shuffle(nums)\n",
    "    X_train =  boards[nums[:100000],:,:,:]\n",
    "    y_train = winners_cat[nums[:100000],:]\n",
    "    \n",
    "    X_test =  boards[nums[100000:200000],:,:,:]\n",
    "    y_test = winners_cat[nums[100000:200000],:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 9s 90us/step - loss: 0.2412 - mean_absolute_error: 0.4834\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 7s 73us/step - loss: 0.2294 - mean_absolute_error: 0.4600\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 8s 77us/step - loss: 0.2234 - mean_absolute_error: 0.4482\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 11s 107us/step - loss: 0.2204 - mean_absolute_error: 0.4413\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 7s 68us/step - loss: 0.2156 - mean_absolute_error: 0.4321\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 9s 92us/step - loss: 0.2118 - mean_absolute_error: 0.4259\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 13s 134us/step - loss: 0.2081 - mean_absolute_error: 0.4169\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 12s 119us/step - loss: 0.2055 - mean_absolute_error: 0.4119\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 11s 108us/step - loss: 0.2017 - mean_absolute_error: 0.4046\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 12s 117us/step - loss: 0.1978 - mean_absolute_error: 0.3967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fba5f9f1748>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, verbose=1, batch_size = BATCH_SIZE,\n",
    "              epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/board_states.npy', 'rb') as boards_file, \\\n",
    "    open('data/winners.npy', 'rb') as winners_file:\n",
    "    boards = np.load(boards_file)\n",
    "    winners = np.load(winners_file)\n",
    "    \n",
    "    #print(boards[10000:20000, :, :, :].shape, winners[100000:20000, :].shape)\n",
    "    \n",
    "#     evaluate = model.evaluate(boards[:10000, :, :, :], winners_cat[10000:20000, :], steps=1)\n",
    "    predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3001813 ,  0.69981873],\n",
       "       [ 0.62609029,  0.37390968],\n",
       "       [ 0.27214527,  0.72785473],\n",
       "       [ 0.40357065,  0.59642935],\n",
       "       [ 0.6465342 ,  0.3534658 ],\n",
       "       [ 0.40723309,  0.59276694],\n",
       "       [ 0.88738459,  0.11261541],\n",
       "       [ 0.09903799,  0.90096205],\n",
       "       [ 0.76009268,  0.23990725],\n",
       "       [ 0.60795599,  0.3920441 ],\n",
       "       [ 0.3198916 ,  0.68010843],\n",
       "       [ 0.59766155,  0.40233847],\n",
       "       [ 0.55590999,  0.44408998],\n",
       "       [ 0.8015765 ,  0.19842348],\n",
       "       [ 0.38053995,  0.61946005],\n",
       "       [ 0.81577802,  0.18422197],\n",
       "       [ 0.28675517,  0.71324486],\n",
       "       [ 0.71685362,  0.28314635],\n",
       "       [ 0.56193882,  0.43806124],\n",
       "       [ 0.59942639,  0.40057358],\n",
       "       [ 0.39276573,  0.60723424],\n",
       "       [ 0.70586663,  0.29413334],\n",
       "       [ 0.35354379,  0.6464563 ],\n",
       "       [ 0.47078317,  0.52921689],\n",
       "       [ 0.86628729,  0.13371277],\n",
       "       [ 0.43263575,  0.56736428],\n",
       "       [ 0.24781899,  0.75218099],\n",
       "       [ 0.38790971,  0.61209029],\n",
       "       [ 0.84327602,  0.15672399],\n",
       "       [ 0.23709588,  0.76290411],\n",
       "       [ 0.39429691,  0.60570312],\n",
       "       [ 0.39315698,  0.60684305],\n",
       "       [ 0.55214959,  0.44785035],\n",
       "       [ 0.14330952,  0.85669053],\n",
       "       [ 0.70428938,  0.29571053],\n",
       "       [ 0.91537267,  0.08462729],\n",
       "       [ 0.13919534,  0.86080468],\n",
       "       [ 0.80921412,  0.19078594],\n",
       "       [ 0.33398262,  0.66601729],\n",
       "       [ 0.35737896,  0.64262104],\n",
       "       [ 0.22482069,  0.77517933],\n",
       "       [ 0.29252708,  0.70747292],\n",
       "       [ 0.64458507,  0.35541499],\n",
       "       [ 0.30002651,  0.69997346],\n",
       "       [ 0.63750458,  0.36249536],\n",
       "       [ 0.46990186,  0.53009814],\n",
       "       [ 0.51435715,  0.48564276],\n",
       "       [ 0.85665107,  0.1433489 ],\n",
       "       [ 0.65590179,  0.34409821],\n",
       "       [ 0.31557548,  0.68442452],\n",
       "       [ 0.71088845,  0.28911158],\n",
       "       [ 0.29414764,  0.70585239],\n",
       "       [ 0.55997813,  0.44002193],\n",
       "       [ 0.12482806,  0.87517196],\n",
       "       [ 0.67657322,  0.32342678],\n",
       "       [ 0.90388471,  0.09611528],\n",
       "       [ 0.2190921 ,  0.78090793],\n",
       "       [ 0.30203673,  0.69796324],\n",
       "       [ 0.96875364,  0.03124636],\n",
       "       [ 0.49544066,  0.50455928],\n",
       "       [ 0.48073262,  0.51926738],\n",
       "       [ 0.25626603,  0.74373394],\n",
       "       [ 0.15150519,  0.84849477],\n",
       "       [ 0.30815575,  0.69184428],\n",
       "       [ 0.80902898,  0.19097103],\n",
       "       [ 0.59837824,  0.40162176],\n",
       "       [ 0.76313657,  0.2368634 ],\n",
       "       [ 0.46664107,  0.53335899],\n",
       "       [ 0.45110562,  0.54889441],\n",
       "       [ 0.4968411 ,  0.50315887],\n",
       "       [ 0.47869849,  0.52130145],\n",
       "       [ 0.24144864,  0.75855136],\n",
       "       [ 0.84190547,  0.15809453],\n",
       "       [ 0.49409273,  0.50590724],\n",
       "       [ 0.75236088,  0.24763909],\n",
       "       [ 0.50809675,  0.49190331],\n",
       "       [ 0.31574145,  0.68425852],\n",
       "       [ 0.63806152,  0.36193848],\n",
       "       [ 0.57338369,  0.42661631],\n",
       "       [ 0.38500372,  0.61499637],\n",
       "       [ 0.3690857 ,  0.63091433],\n",
       "       [ 0.2615912 ,  0.73840886],\n",
       "       [ 0.27452642,  0.72547364],\n",
       "       [ 0.92002612,  0.07997383],\n",
       "       [ 0.37491065,  0.62508929],\n",
       "       [ 0.46737796,  0.53262204],\n",
       "       [ 0.04466465,  0.95533538],\n",
       "       [ 0.31208152,  0.68791848],\n",
       "       [ 0.52073908,  0.47926089],\n",
       "       [ 0.49628899,  0.50371104],\n",
       "       [ 0.41866603,  0.58133399],\n",
       "       [ 0.04553692,  0.95446306],\n",
       "       [ 0.24568744,  0.75431263],\n",
       "       [ 0.31355155,  0.68644845],\n",
       "       [ 0.10112225,  0.8988778 ],\n",
       "       [ 0.96233028,  0.03766973],\n",
       "       [ 0.25000629,  0.74999374],\n",
       "       [ 0.57725215,  0.42274785],\n",
       "       [ 0.62481844,  0.37518156],\n",
       "       [ 0.13272631,  0.86727375]], dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "predict[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
